# BFD-2022-2023
Business and financial Data Guidolin
---
title: "Business Economic and Financial Data Project"
author: "Brenda Eloísa Téllez Juárez, Angelica Giangiacomi, Pietro Sanguin"
date: "2022-11-27"
output:
  powerpoint_presentation: default
  slidy_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
##Setting the working directory
#```{r}
#bren<-setwd("~/UNIPD/Business, economics and financial data")
#```

## Packages
```{r}
#Dataset
library(readxl)
#Create the pdf
library(knitr)
library(markdown)
library(commonmark)
#missing values
library(naniar)
#Visualizations
library(ggplot2)
library(tidyverse)
library(plotly)
library(DiagrammeR)
#Correlation and multicollinearity
library(ellipse)
library(car)
#Inspecting the dataframe
library(inspectdf)
#Time series
library(fpp2)
library(forecast)
library(lmtest)
library(gam)
#Gradient Boosting Model
library(gbm)
library(xgboost)
library(caret)
#Mine
library(ts.extend)
library(tseries)
library(caTools)
# Bass Models
library(DIMORA)

set.seed(50)
```

#Dataset
```{r}
database1 <- read_excel("database1.xlsx")
data<-database1
attach(data)
```
#Dataset
```{r}
head(data, n=5)
tail(data, n=5)
```


#Understanding the data
```{r}
summary(data)
str(data)
sapply(data, class)
```
```{r}
print(start(GSPC))
print(end(GSPC))
print(frequency(GSPC))
print(deltat(GSPC))
print(cycle(GSPC))
```

#Data engineering

##Searching for null values
```{r}
sapply(data, function(x) round((sum(is.na(x))/length(x))*100,2))
#Visualizing them
gg_miss_var(data)
```

#Data transformations

##Renaming columns
```{r}
colnames(data) <- c('Year', "VIX",'VIX returns',  "Inflation",'Population', "Real interest rate", "GDP", "GDP per capita", "GNI",'GSPC returns', "GSPC")
columns <- colnames(data)
```

##Copy of the original dataframe
```{r}
data2 <- data.frame(data)
```

#Data engineering

##Null values
```{r}
data <-replace(data, is.na(data), 0)
```

##Checking null values
```{r}
sapply(data, function(x) round((sum(is.na(x))/length(x))*100,2))
```
##Visualizing them
```{r}
gg_miss_var(data)
```
#Exploratory Data Analysis

##Dimension of the dataset
```{r}
dim(data)
```
##Exploring the dataset
```{r}
head(data)
tail(data)
```
#Univariate Analysis

##Visualizing distributions
```{r}
dens_vix <- density(log(data$VIX))
 
plot_ly(
  data = data,
  x = ~log(VIX),
  type = "histogram",
  name = "Histogram") %>% 
  add_lines(x = dens_vix$x, y = dens_vix$y, yaxis = "y2", name = "Density") %>% 
  layout(yaxis2 = list(overlaying = "y", #Adds the dual y-axis
                       side = "right", #Adds the density axis on the right side
                       rangemode = "tozero")) #Forces both y-axes to start at 0

```
```{r}
dens_gspc <- density(log(data$GSPC))
 
plot_ly(
  data = data,
  x = ~log(GSPC),
  type = "histogram",
  name = "Histogram") %>% 
  add_lines(x = dens_gspc$x, y = dens_gspc$y, yaxis = "y2", name = "Density") %>% 
  layout(yaxis2 = list(overlaying = "y", #Adds the dual y-axis
                       side = "right", #Adds the density axis on the right side
                       rangemode = "tozero")) #Forces both y-axes to start at 0
```
```{r}
dens_gdp <- density(log(data$GDP))
 
plot_ly(
  data = data,
  x = ~log(GDP),
  type = "histogram",
  name = "Histogram") %>% 
  add_lines(x = dens_gdp$x, y = dens_gdp$y, yaxis = "y2", name = "Density") %>% 
  layout(yaxis2 = list(overlaying = "y", #Adds the dual y-axis
                       side = "right", #Adds the density axis on the right side
                       rangemode = "tozero")) #Forces both y-axes to start at 0
```

#Bivariate Analysis

##Analizing the relationship between VIX and GSPC
```{r}
data %>% 
  ggplot() + 
  aes(x = VIX, y = GSPC) + 
  geom_point(color= "steelblue") +
  geom_smooth(method = 'lm', color = 'purple') 
```
```{r}
ggplot(data, 
       aes(x = VIX, 
           y = GSPC)) +
  geom_point(color= "steelblue") +
  geom_smooth(method = "lm", 
              formula = y ~ poly(x, 2), 
              color = "purple")
```
##Analizing the relationship between the returns of VIX and GSPC
```{r}
data %>% 
  ggplot() + 
  aes(x = `VIX returns`, y = `GSPC returns`) + 
  geom_point(color= "steelblue") +
  geom_smooth(method = 'lm', color = 'purple', formula = y ~ poly(x, 2)) 
```


##Analizing the relationship between GDP and GSPC
```{r}
data %>% 
  ggplot() + 
  aes(x = GDP, y = GSPC) + 
  geom_point(color= "steelblue") +
  geom_smooth(method = 'lm', color = 'purple') 
```
```{r}
data %>% 
  ggplot() + 
  aes(x = VIX, y = GSPC) + 
  geom_point(color= "steelblue") +
  geom_smooth(method = 'lm', color = 'purple',formula=y ~ poly(x, 2)) 
```
##Analizing the relationship between the returns of GDP and GSPC
```{r}
data %>% 
  ggplot() + 
  aes(x = `VIX returns`, y = `GSPC returns`) + 
  geom_point(color= "steelblue") +
  geom_smooth(method = 'lm', color = 'purple',formula=y ~ poly(x, 2)) 
```


##Analizing the relationship between VIX and GDP
```{r}
data %>% 
  ggplot() + 
  aes(x = VIX, y = GDP) + 
  geom_point(color= "steelblue") +
  geom_smooth(method = 'lm', color = 'purple') 
```
```{r}
data %>% 
  ggplot() + 
  aes(x = VIX, y = GDP) + 
  geom_point(color= "steelblue") +
  geom_smooth(method = 'lm', color = 'purple', formula=y ~ poly(x, 2)) 
```


#Time series analysis: Linear regression and Arima models.

##Plot GSPC
```{r}
x <- year
y <- GSPC
data_graph1 <- data.frame(x, y)

fig <- plot_ly(data_graph1, x = x, y = y, type = 'scatter', mode = 'lines')

fig
```
##Plot GSPC returns
```{r}
x <- year
y <- `GSPC returns`
data_graph1 <- data.frame(x, y)

fig <- plot_ly(data_graph1, x = x, y = y, type = 'scatter', mode = 'lines')

fig
```

#AFC GSPC
```{r}
Acf_GSPC<-ggAcf(GSPC, col='blue')
Acf_GSPC+ ggtitle("Autocorrelation Function ACF") + xlab("Lag") + ylab("ACF")
```
#PACF GSPC
```{r}
Pacf_GSPC<-ggAcf(GSPC, col='blue')
Pacf_GSPC+ ggtitle("Partial Autocorrelation Function PACF GSPC") + xlab("Lag") + ylab("PACF")
```
##Plot VIX
```{r}
x <- year
y <- VIX
data_graph2 <- data.frame(x, y)

fig <- plot_ly(data_graph2, x = ~x, y = ~y, type = 'scatter', mode = 'lines')
fig
```
##Plot VIX returns
```{r}
x <- year
y <- `VIX returns`
data_graph2 <- data.frame(x, y)

fig <- plot_ly(data_graph2, x = ~x, y = ~y, type = 'scatter', mode = 'lines')
fig
```

##AFC VIX
```{r}
Acf_GSPC<-ggAcf(VIX, col='blue')
Acf_GSPC+ ggtitle("Autocorrelation Function VIX") + xlab("Lag") + ylab("ACF")
```
##PACF VIX
```{r}
Pacf_GSPC<-ggAcf(VIX, col='blue')
Pacf_GSPC+ ggtitle("Partial Autocorrelation Function PACF VIX") + xlab("Lag") + ylab("PACF")
```
##Plot GDP
```{r}
x <- year
y <- GDP
data_graph3 <- data.frame(x, y)

fig <- plot_ly(data_graph3, x = ~x, y = ~y, type = 'scatter', mode = 'lines')

fig
```

##AFC GDP
```{r}
Acf_GSPC<-ggAcf(GDP, col='blue')
Acf_GSPC+ ggtitle("Autocorrelation Function GDP") + xlab("Lag") + ylab("ACF")
```

##PACF GDP

```{r}
Pacf_GSPC<-ggAcf(GDP, col='blue')
Pacf_GSPC+ ggtitle("Partial Autocorrelation Function PACF GDP") + xlab("Lag") + ylab("PACF")
```

#Time Series

```{r}
#Creating the time series
ts1_GSPC<-ts(GSPC, start = 1990, end=2021, frequency = 1)
ts2_VIX<-ts(VIX, start = 1990, end=2021, frequency = 1)
ts3_GDP<-ts(GDP, start = 1990, end=2021, frequency = 1)
is.ts(ts1_GSPC)
```

```{r}
#Returns
ts1_GSPC_returns<-ts(`GSPC returns`, start = 1990, end=2021, frequency = 1)
ts2_VIX_returns<-ts(`VIX returns`, start = 1990, end=2021, frequency = 1)
```

#Transforming the time series with log and differenciating them
##Aplying the log transformation

```{r}
#Applying log transformations to try to stabilize the variance
ts1_GSPC_log<-log(ts1_GSPC)
par(mfrow=c(1,2))
ts.plot(ts1_GSPC_log)
ts.plot(ts1_GSPC)
```

```{r}
#Applying log transformations
ts2_VIX_log<-log(ts2_VIX)
par(mfrow=c(1,2))
ts.plot(ts2_VIX_log)
ts.plot(ts2_VIX)
```
##Aplying the diff transformation

```{r}
#Applying diff transformations to eliminate the linear trend
ts1_GSPC_diff<-diff(ts1_GSPC)
par(mfrow=c(1,2))
ts.plot(ts1_GSPC_diff)
ts.plot(ts1_GSPC)
```

```{r}
#Applying diff transformations
ts2_VIX_diff<-diff(ts2_VIX)
par(mfrow=c(1,2))
ts.plot(ts2_VIX_diff)
ts.plot(ts2_VIX)
```


##Aplying the diff seasonal transformation

```{r}
#Applying diff transformations to eliminate the linear trend and seasonality
ts1_GSPC_diff_s<-diff(ts1_GSPC, s=2)
par(mfrow=c(1,2))
ts.plot(ts1_GSPC_diff_s)
ts.plot(ts1_GSPC_diff)
ts.plot(ts1_GSPC)
```
```{r}
#Applying diff seasonality transformations
ts2_VIX_diff_s<-diff(ts2_VIX, lag=12)
par(mfrow=c(1,2))
ts.plot(ts2_VIX_diff_s)
ts.plot(ts2_VIX_diff)
ts.plot(ts2_VIX)
```

```{r}
#Exploring the length
length(ts1_GSPC)
length(ts1_GSPC_diff)
length(ts2_VIX)
length(ts2_VIX_diff)
```

#Estimating the white noise


```{r}
#Estimating white noise for GSPC
arima(ts1_GSPC, order=c(0,0,0))
```
```{r}
#Estimating white noise for VIX
arima(ts2_VIX, order=c(0,0,0))
```


```{r}
#Applying differentiated model GSPC
model_wn_gspc<-arima(ts1_GSPC_diff, order=c(0,0,0))
int_wn_gspc <- model_wn_gspc$coef
```

```{r}
ts.plot(ts1_GSPC)
abline(0,int_wn_gspc)
```

```{r}
#Applying differentiated model VIX
model_wn_vix<-arima(ts2_VIX_diff, order=c(0,0,0))
int_wn_vix<- model_wn_vix$coef
```

```{r}
ts.plot(ts2_VIX)
abline(0,int_wn_vix)
```

##Plotting the two indexes together

```{r}
ts.plot(cbind(ts1_GSPC, ts2_VIX))
```

```{r}
#Log returns for both indexes
plot(cbind(ts1_GSPC_returns, ts2_VIX_returns))
```
## Now we can take a look at the correlations between the predictors
```{r}
library(ellipse)
# plot correlation ellipses
plotcorr(cor(data))

```
# we can see that there are are some features that are correlated,
# most of them are expected, like GDP with GDP per capita and VIX with VIX returns 
# and other (maybe) less intuitive, like population with GDP
# thus we select only one of them (because if they are correlated, than using both of them is redundant)




## Now we check for multicollinearity

```{r}
# compute VIFs

model <- lm(data$GSPC~data$VIX+data$GNI+data$Population+data$Inflation+data$`Real interest rate`+data$GDP) 
vif(model)
```

```{r}
model <- lm(data$VIX~data$GSPC+data$GNI+data$Population+data$Inflation+data$`Real interest rate`+data$GDP)
vif(model)
```

```{r}
model <- lm(data$GNI~data$GSPC+data$VIX+data$Population+data$Inflation+data$`Real interest rate`+data$GDP)
vif(model)
```

```{r}
model <- lm(data$Population~data$GSPC+data$VIX+data$GNI+data$Inflation+data$`Real interest rate`+data$GDP)
vif(model)
```

```{r}
model <- lm(data$Inflation~data$GSPC+data$VIX+data$GNI+data$Population+data$`Real interest rate`+data$GDP)
vif(model)
```

```{r}
model <- lm(data$`Real interest rate`~data$GSPC+data$VIX+data$GNI+data$Population+data$Inflation+data$GDP)
vif(model)
```

```{r}
model <- lm(data$GDP~data$GSPC+data$VIX+data$GNI+data$Population+data$Inflation+data$`Real interest rate`)
vif(model)
```
# From the results above we can notice we have a strong situation of multicollinearity.
# We have that the highest values are the VIF values computed for GNI, population and GDP


# Now we compute the VIFs without considering GNI, population and GDP predictors (i.e. those ones having the highest VIF values)

```{r}
model <- lm(data$GSPC~data$VIX+data$Inflation+data$`Real interest rate`) 
vif(model)
```
```{r}
model <- lm(data$VIX~data$GSPC+data$Inflation+data$`Real interest rate`)
vif(model)
```

```{r}
model <- lm(data$Inflation~data$GSPC+data$VIX+data$`Real interest rate`)
vif(model)
```

```{r}
model <- lm(data$`Real interest rate`~data$GSPC+data$VIX+data$Inflation)
vif(model)
```
# in the cell above we obtain great results from VIFs
# thus we are going to use only the following four predictors: GSPC, VIX, inflation, interest_rate
# because all the others are redundant, due to strong correlation or very high VIF values
# (btw, I know this is a repetition, but it is just to clarify)


#Autoregressive model AR Inflation
```{r}
ts.plot(data$Inflation)
AR_inflation <- arima(data$Inflation, order = c(1,0,0))
AR_inflation_fitted<- data$Inflation - residuals(AR_inflation)
points(AR_inflation_fitted, type='l', col="red", lty=2)
```
Forecasting
```{r}
predict(AR_inflation, n.ahead=6)$pred
```

```{r}
predict(AR_inflation, n.ahead=6)$se
```
#Moving average process MA inflation

```{r}
ts.plot(data$Inflation)
MA_inflation <- arima(data$Inflation, order = c(0,0,1))
MA_inflation_fitted<- data$Inflation - residuals(MA_inflation)
points(MA_inflation_fitted, type='l', col="red", lty=2)
```
#Forecast

```{r}
predict(MA_inflation, n.ahead=6)$pred
```
```{r}
predict(MA_inflation, n.ahead=6)$se
```
#Correlation between AR and MA
```{r}
cor(AR_inflation_fitted, MA_inflation_fitted)
```
#AIC & BIC of AR Inflation
```{r}
AIC(AR_inflation)
BIC(AR_inflation)
```
#AIC & BIC of MA Inflation
```{r}
AIC(MA_inflation)
BIC(MA_inflation)
```
```{r}
arima11<- Arima(GSPC, order=c(1,0,1))
fitted(arima11)

resid1<- residuals(arima11)
tsdisplay(resid1)

plot(GSPC, type='l')
lines(fitted(arima11), col=2)

for1<- forecast(arima11)
plot(for1)
```
```{r}
plot(GSPC, ylab="GSPC index",xlab="year")
tsdisplay(GSPC)
diff1<- diff(GSPC)
tsdisplay(diff1)

####we fit the first Arima model  
a1<- Arima(GSPC, order=c(1,0,1), seasonal=c(0,0,1))
fit1<- fitted(a1)

plot(GSPC, type = 'l')
lines(fit1, col=2)

f1<- forecast(a1)
plot(f1)

r1<- residuals(a1)
tsdisplay(r1) 
```

```{r}
auto.a<- auto.arima(GSPC)
auto.a

plot(forecast(auto.a))
```

```{r}
autoplot(ts(data))
```



```{r}
tsdisplay(GSPC)
```

```{r}
par(mfrow=c(1,1))
armax1<- Arima(GSPC, xreg=VIX, order=c(1,1,2))
res1<- residuals(armax1)
Acf(res1)
fitted(armax1)
plot(GSPC, type='l')
lines(fitted(armax1), col=2)
```
```{r}
armax2<- Arima(GSPC, xreg=VIX, order=c(1,1,1))
res2<- residuals(armax2)
Acf(res2)

fitted(armax2)
plot(GSPC, type='l')
lines(fitted(armax2), col=2)
AIC(armax2)
AIC(armax1)
```
```{r}
armax3<- auto.arima(GSPC, xreg=VIX)
res3<- residuals(armax3)
Acf(res3)

fitted(armax3)
plot(GSPC, type='l')
lines(fitted(armax3), col=2)
```
```{r}
AIC(armax3)
AIC(armax2)
AIC(armax1)
```
#doesnt work the tslm

#Dividing the dataset in training and testing

```{r}
set.seed(123)
split = sample.split(GSPC, SplitRatio = 2/3)
training_set = subset(data, split == TRUE)
test_set = subset(data, split == FALSE)
```

#Linear model
```{r}
m1 <- lm(GSPC~., data=training_set)
summary(m1)
```
```{r}
par(mfrow=c(2,2))
plot(m1)
par(mfrow=c(1,1))
```
```{r}

m1.graph<-ggplot(data, aes(x=data$GSPC, y=data$Population))+
                     geom_point() + geom_smooth(method="lm", col="pink") +
  labs(title = "GSPC as a function of Population",
      x = "GSPC",
      y = "Population")

m1.graph
```



```{r}
m2 <- lm(data$GSPC~ data$Population +data$GNI, data=training_set)
summary(m2)
```
```{r}
par(mfrow=c(2,2))
plot(m2)
par(mfrow=c(1,1))
```


```{r}
m3 <- lm(data$GSPC~data$Population, data=training_set)
summary(m3)
```
```{r}
par(mfrow=c(2,2))
plot(m3)
par(mfrow=c(1,1))
```

```{r}
m4 <- step(m1, direction="both")
summary(m4)
```
```{r}
m5 <- lm(data$GSPC~data$Population +data$Year+ data$VIX+ data$GNI+ data$`GSPC returns`, data=training_set)
summary(m5)
```
```{r}
par(mfrow=c(2,2))
plot(m5)
par(mfrow=c(1,1))
```


#Prediction
```{r}
p.lm <- predict(m5, newdata=test_set)
dev.lm <- sum((p.lm-test_set$GSPC)^2)
dev.lm

AIC(m5)
```
#Stepwise GAM

```{r}
g1 <- gam(GSPC~., data=training_set)
```

```{r}
par(mfrow=c(3,5))
plot(g1, se=T, col='pink') 
```

#GBM
```{r}
library(caret)
# Partition into training and test data
set.seed(42)
index <- createDataPartition(data$GSPC, p = 0.7, list = FALSE)
train_data <- data[index, ]
test_data  <- data[-index, ]
```

```{r}
head(test_data)
```

```{r}
# Train model with preprocessing & repeated cv
library(xgboost)

xgboost_model <- xgboost(data = as.matrix(train_data[, -1]), 
                         label = as.numeric(train_data$GSPC)-1,
                         max_depth = 3, 
                         objective = 'reg:squarederror', 
                         nrounds = 10, 
                         verbose = FALSE,
                         prediction = TRUE)
xgboost_model
```
```{r}
yhat.boost<-predict(xgboost_model, 
        as.matrix(test_data[, -1])) %>%
  as.tibble() %>%
  mutate(prediction = round(value),
         label = as.numeric(test_data$GSPC)-1) %>%
  count(prediction, label)
yhat.boost
```
```{r}
summary(xgboost_model)
```
```{r}
# Plot with all the trees
library(DiagrammeR)
xgb.plot.tree(model = xgboost_model)
```
```{r}
#The below code is to plot first tree and show its node ID
xgb.plot.tree(model = xgboost_model, trees = 0, show_node_id = TRUE)
```
```{r}
#With advance settings
dtrain <- xgb.DMatrix(as.matrix(train_data[, -1]), 
                      label = as.numeric(train_data$GSPC)-1)
dtest <- xgb.DMatrix(as.matrix(test_data[, -1]), 
                      label = as.numeric(test_data$GSPC)-1)

params <- list(max_depth = 3, 
               objective = 'reg:squarederror',
               silent = 0)

watchlist <- list(train = dtrain, eval = dtest)

bst_model <- xgb.train(params = params, 
                       data = dtrain, 
                       nrounds = 10, 
                       watchlist = watchlist,
                       verbose = FALSE,
                       prediction = TRUE)
bst_model
```
```{r}
predict(bst_model, 
        as.matrix(test_data[, -1])) %>%
  as.tibble() %>%
  mutate(prediction = round(value),
         label = as.numeric(test_data$GSPC)-1) %>%
  count(prediction, label)
```
```{r}
# Plot with all the trees
library(DiagrammeR)
xgb.plot.tree(model = bst_model)
```
```{r}
#The below code is to plot first tree and show its node ID
xgb.plot.tree(model = bst_model, trees = 0, show_node_id = TRUE)
```
```{r}
#Cross validation
cv_model <- xgb.cv(params = params,
                   data = dtrain, 
                   nrounds = 100, 
                   watchlist = watchlist,
                   nfold = 5,
                   verbose = FALSE,
                   prediction = TRUE) # prediction of cv folds
cv_model
```
```{r}
#we can see after how many rounds, we achieved the smallest test error
cv_model$evaluation_log %>%
  filter(test_rmse_mean == min(test_rmse_mean))
```
#The graph between predicted values is missing




# Bass Model, GGM
```{r}
# implement a simple Bass Model
bass1 <- BM(data$GSPC, display=T)
```

```{r}
# see the results of the simple BM
summary(bass1)
```

```{r}
###prediction using simple BM (out-of-sample)
pred_bass1 <- predict(bass1, newx=c(1:50))
pred.inst.bm1 <- make.instantaneous(pred_bass1)
```

```{r}
###plot of fitted model 
plot(data$GSPC, type= "b",xlab="Year", ylab="GSPC",  pch=16, lty=3, xaxt="n", cex=0.6)
axis(1, at=c(1,10,19,28,32), labels=data$Year[c(1,10,19,28,32)])
lines(pred.inst.bm1, lwd=2, col=2)
```

```{r}
# implement a simple Bass Model using 80% of the observations
bass2 <- BM(data$GSPC[1:26], display=T)
```


```{r}
# see the results of the BM2
summary(bass2)
```

```{r}
###prediction using BM 2 (out-of-sample)
pred_bass2 <- predict(bass2, newx=c(1:50))
pred.inst.bm2 <- make.instantaneous(pred_bass2)
```

```{r}
###plot of fitted model 
plot(data$GSPC[1:24], type= "b",xlab="Year", ylab="GSPC",  pch=16, lty=3, xaxt="n", cex=0.6)
axis(1, at=c(1,5,10,17,24), labels=data$Year[c(1,5,10,17,24)])
lines(pred.inst.bm1, lwd=2, col=2)
```

```{r}
###Comparison between models (instantaneous)
plot(data$GSPC, type= "b",xlab="Year", ylab="GSPC",  pch=16, lty=3, xaxt="n", cex=0.6)
axis(1, at=c(1,5,10,17,24,32), labels=data$Year[c(1,5,10,17,24,32)])
lines(pred.inst.bm1, lwd=2, col=2)
lines(pred.inst.bm2, lwd=2, col=3)
```
```{r}
###Comparison between models (cumulative)
plot(cumsum(data$GSPC), type= "b",xlab="Year", ylab="GSPC",  pch=16, lty=3, xaxt="n", cex=0.6)
axis(1, at=c(1,5,10,17,24,32), labels=data$Year[c(1,5,10,17,24,32)])
lines(pred_bass1, lwd=2, col=2)
lines(pred_bass2, lwd=2, col=3)
```

# NO visible, possible shocks (exponential neither rectangular),
# so let's directly implement GGM

```{r}
# implement a GGM considering prelimestimates=NULL
# because of no visible shock
ggm1 <- GGM(data$GSPC)
```


```{r}
# see the results of GGM
summary(ggm1)
```

```{r}
pred_GGM<- predict(ggm1, newx=c(1:40))
pred_GGM.inst<- make.instantaneous(pred_GGM)
```

```{r}
plot(data$GSPC, type= "b",xlab="Year", ylab="GSPC",  pch=16, lty=3, xaxt="n", cex=0.6)
axis(1, at=c(1,5,10,17,24,32), labels=data$Year[c(1,5,10,17,24,32)])
lines(pred_GGM.inst, lwd=2, col=2)
```

```{r}
###Comparison between models (instantaneous)
plot(data$GSPC, type= "b",xlab="Year", ylab="GSPC",  pch=16, lty=3, xaxt="n", cex=0.6)
axis(1, at=c(1,5,10,17,24,32), labels=data$Year[c(1,5,10,17,24,32)])
lines(pred.inst.bm1, lwd=2, col=2)
lines(pred.inst.bm2, lwd=2, col=3)
lines(pred_GGM.inst, lwd=2, col=4)
```
